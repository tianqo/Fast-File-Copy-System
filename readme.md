# 文件快速拷贝系统

## 引言

在Windows下，有一个名为`fastcopy`的软件，它的存在是为了提高文件拷贝速度。实测显示，相较于Windows自带的拷贝工具，`fastcopy`的速度提升了1.7倍。

同样，在Linux中，有一个快速拷贝的方式——命令行工具`tar`，其复制速度与`fastcopy`相差无几。

此外，还有一个索引软件`everything`，它能提升文件索引的速度。

## 分析

### FastCopy

* **多线程技术**：将大文件的复制任务分解成多个小任务，每个任务由独立的线程负责处理。
* **并行数据传输**：多个线程同时进行数据传输，充分利用多核处理器的资源，提高效率。
* **异步I/O**：在后台进行数据读取和写入操作，不阻塞主线程，避免性能瓶颈。
* **直接I/O**：绕过操作系统缓存，直接从硬盘读取数据并写入目标位置，减少内存中的数据拷贝次数。
* **智能调度算法**：根据文件大小、传输距离和网络环境等因素优化数据传输过程。
* **缓冲区优化**：利用缓冲区暂存要传输的数据，减少磁盘I/O操作的次数。

### Tar

命令示例：
```bash
tar -cf - /src_directory | pv | tar -xpf - -C /dest_directory
```

- `-c`：创建压缩包。
- `-f -`：输出到标准输出。
- `pv`：显示进度。
- `-x`：解压。
- `-C`：指定解压的目标目录。

其主要目的是减少对大量小文件的索引时间，同时**歪打正着**地进行了排序。

*注：排序指的是对文件大小的复制优先级排序。*

### Everything

1. **NTFS文件系统与USN日志**
   * NTFS（New Technology File System）是Windows NT及以上版本的默认文件系统，记录了文件与目录的相关信息。
   * USN日志（Update Sequence Number Journal）用于记录文件系统的变更情况，如文件的创建、删除、重命名等。
   * **工作原理**：Everything通过读取并解析NTFS文件系统的USN日志，获取所有文件和文件夹的信息，而不是像传统搜索工具那样遍历整个文件系统。这大大减少了搜索所需的时间。

2. **索引数据库**
   * **首次运行**：当Everything首次运行时，它会扫描整个硬盘，并将所有文件和文件夹的名称、路径、大小、创建时间等信息提取出来，存储在一个轻量级的索引数据库中。
   * **索引更新**：随着文件系统的变更（如文件的增删改查），Everything会实时更新索引数据库，确保搜索结果的准确性。这种更新是异步进行的，不会干扰用户的搜索操作。

## 二次分析

从上述内容可以看出，这些程序的存在都是为了优化Windows系统。其中：
- **FastCopy**的核心是多线程技术。
- **tar**的核心是归档功能。
- **Everything**的核心是索引功能。

虽然这些工具在各自的领域表现出色，但也存在一些问题：
- **FastCopy**：没有建立快速索引，在首次使用后可以在硬盘内单独建立一个索引库，以优化下次的复制操作。
- **FastCopy**：缺乏碎片文件归档。尽管已经支持多线程，但可以在拷贝大文件的同时，增加一个归档小文件的进程。

如果能解决这些优化问题，文件的转移速度将得到显著提升。通过结合上述三者的功能，我们可以实现一个更高效的文件快速拷贝系统。

## 总结

基于目前的想法，主要有以下几个方面：

1. 尝试复刻**FastCopy**的基本算法和异步多线程。
   * 暂时不考虑过于复杂的绕过缓存和缓存复制。
2. 尝试复刻**tar**的归档功能。
3. 尝试复刻**Everything**的索引功能，并额外增加索引的导出。
4. 选择**Golang语言**而不是Python，因为Golang相较于C更方便，而相较于Python则更接近底层。

通过结合上述三者的功能，我们可以实现一个最基本的文件快速拷贝系统，能够在不超过100GB的文件下进行复制操作，且不会出现系统资源占用过高等问题。所有测试将使用38GB的“我的世界”游戏文件夹进行，其中约15%为大文件，85%为完全碎片化文件。
