# 文件快速拷贝系统

## 引言

在windows下有一个名为```fastcopy```的软件，他的存在是为了提高文件拷贝速度，实测相较于windows自带的拷贝工具，```fastcopy```的速度提升了1.7倍。

相同的，linux也存在一个快速拷贝的方式，命令行名为```tar```，一个压缩命令。他的复制速度与```fastcopy```相差无几。

最后还有一个索引软件```everything```，提升文件索引速度。

## 分析

### FastCopy

* 利用多线程技术，将大文件的复制任务分解成多个小任务，每个任务由独立的线程负责处理。
* 多个线程可以同时进行数据传输，充分利用多核处理器的计算资源，提高数据传输的并行度和效率。
* 异步I/O：在后台进行数据读取和写入操作，不阻塞主线程，避免因等待I/O操作而导致的性能瓶颈。
* 直接I/O：绕过操作系统缓存，直接从硬盘读取数据并写入目标位置，减少数据在内存中的拷贝次数。
* 根据文件大小、传输距离和网络环境等因素，采用智能调度算法优化数据传输过程。
* 利用缓冲区暂存要传输的数据，减少磁盘I/O操作的次数。

### tar

`tar -cf - /src_directory | pv | tar -xpf - -C /dest_directory `

* -c：创建压缩包。
* -f -：输出到标准输出。
* pv：查看进度。
* -x：解压。
* -C：指定解压的目标目录。

其目的主要是减少对大量小文件的索引时间，并且**歪打正着**的排了序*。

~ *排序指对文件大小复制优先级的排序~

### Everything

1. 利用NTFS文件系统的USN日志：

* **NTFS文件系统**：NTFS（New Technology File System）是Windows NT及以上版本的默认文件系统。它包含一个元数据系统，详细记录了文件与目录的相关信息，如文件名、大小、创建与修改时间等。
* **USN日志**：NTFS文件系统中存在一个USN日志（Update Sequence Number Journal），用于记录文件系统中的所有变更，如文件的创建、删除、重命名等。
* **工作原理**：Everything通过读取并解析NTFS文件系统的USN日志，获取所有文件和文件夹的信息，而不是像传统搜索工具那样遍历整个文件系统。这种方式大大减少了搜索所需的时间。

2. 建立索引数据库：

* **首次运行**：当Everything首次运行时，它会扫描整个硬盘，将所有文件和文件夹的名称、路径、大小、创建时间等信息提取出来，并存储在一个轻量级的索引数据库中。
* **索引更新**：随着文件系统的变化（如文件的增删改查），Everything会实时更新索引数据库，确保搜索结果的准确性。这种更新是异步进行的，不会干扰用户的搜索操作。

## 二次分析

所以可以看到，这些程序的存在都是为了优化windows而存在，其中```fastcopy```的核心是多线程，```tar```的核心是归档，```everything```的核心是索引。换言之，除了```tar```这个独属于linux的命令外，其他的功能windows都**没有**亦或是**不完善**。

虽说是优化，但他们各自也有一点问题，尤其是fastcopy：

* fastcopy：
  1. 没有建立快速索引，虽然对于移动储存介质来说并不需要这个操作，~（因为有了反而会变慢）~，但不外乎可以询问用户是否在第一次使用以后单独在硬盘内建立一个索引库，以便于下次的复制操作。
  2. 没有碎片文件归档。其实这才是我认为其最大的问题，因为在已经使用多线程的情况下，完全可以在拷贝大文件的进程下，再建立一个归档小文件的进程。
     * 以我400GB的硬盘为例，其中小文件占有量高达60%。复制硬盘中20GB的电影需要花费15~20分钟，这些时间可以压缩掉40%左右的碎片文件，在拷完大文件之前完全可以完成这些操作，此后再复制压缩包就会少掉很多时间。

如果能解决这个问题，文件的转移速度将大大提升。上述的几个程序相结合，我认为就是一个完美的文件转移系统。

## 总结

以目前的想法来看，主要有以下几个方面：

1. 尝试复刻```fastcopy```的基本算法和异步多线程。暂时不考虑过于复杂的绕过缓存和缓存复制。
2. 尝试复刻```tar```的归档功能。
3. 尝试复刻```everything```的索引功能，并额外增加索引的导出。
4. 使用golang语言而不是python，相比于C，它更方便，相比于python，它跟底层。
5. 结合上述三者的功能，实现一个最基本的文件快速拷贝系统。

*其中最基本指的是能够在不超过100GB的文件下进行复制操作，其中不会出现系统资源沾满、内存占用过高等情况。所有测试将会使用38GB的“我的世界”游戏文件夹进行测试，其中约15%为大文件，85%为完全碎片化文件。*